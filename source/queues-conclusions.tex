%==============================================================================
% queues-conclusions.tex
%==============================================================================

\chapter{Conclusions and Future Work}
\label{chap:queues-conclusions-and-future-work}

\section{Conclusions}
\label{sec:queues-conclusions-and-future-work-conclusions}

Our hypothesis was that we could improve the performance of the
intervals scheduler with non-blocking work-stealing queues. Thus, we
designed and implemented several work-stealing queues.

We evaluated the performance of our queue implementations by using the
intervals implementations of various Java Grande Forum
benchmarks. None of the work-stealing queues we developed
significantly improves work-stealing performance on the machines we
had to test them with: The runtime of the benchmarks using our
implementations of the work-stealing queue, \emph{Work-Stealing Deque}
and \emph{Idempotent Work-Stealing Deque}, with the original
\emph{Work-Stealing Lazy Deque} are almost the same. The alternative
queue implementations, \emph{Dynamic Work-Stealing Deque},
\emph{Idempotent FIFO Work-Stealing Queue}, and \emph{Idempotent LIFO
  Work-Stealing Queue} are often significantly slower then the other
queues. The \emph{Duplicating Work-Stealing Queue}'s performance is
comparable to the \emph{Idempotent Work-Stealing Deque}.

Apart from the complexer implementation compared to the original
\emph{Work-Stealing Lazy Deque}, a possible reason for this could be
the rather small number of cores of our benchmark machines (Appendix
\ref{chap:experimental-setup}). As \textcite{Saha2007} state, there is
no noticeable difference between the speedup of work-stealing and a
global shared work queue when not using more than 8 cores. Our
experiments confirmed those findings for the JGF benchmarks. There is
no significant difference between the runtimes of the different
implementations -- whether we use work-stealing or the single shared
work queue, we get almost the same results.


\section{Future Work}
\label{sec:queues-conclusions-and-future-work-future-work}

Given the results of the performance evaluation, a direction for
future research would be to explore the performance of the different
work-stealing queue implementations on machines featuring more than 8
cores.

It may also be interesting to see how our work-stealing queues would
benefit from using the steal-half algorithm of \textcite{Hendler2002}.

One disadvantage of the queues using arrays to maintain work items is
that they do not shrink them again once the queue contains less work
items. This might result in a big waste of
memory. \textcite{Chase2005} present a way of shrinking an array
without copying by keeping the reference to the smaller array when
expanding. When the queue shrinks back its array to the smaller
previous array, only the elements that were modified while the larger
array was active need to be copied.

Another optimization \textcite{Chase2005} mention is working with a
shared pool of arrays. With the shared pool implementation, whenever
the queue needs a larger array, it allocates one of the appropriate
size from the pool, and whenever it shrinks to a smaller array and
does not need the larger array anymore, it can return it to the pool.


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
