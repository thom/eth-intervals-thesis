%==============================================================================
% benchmarks.tex
%==============================================================================

\chapter{Benchmarks}
\label{chap:appendix-benchmarks}

\section{Java Grande Forum}
\label{sec:benchmarks-jgf}

We evaluate the \emph{intervals} work-stealing queues on a variety of
parallel Java Grande Forum benchmarks \cite{Smith2001}
\cite{Mathew1999} \cite{Gregg2003} ported to use \emph{intervals}.

The JVM used on both machines described in appendix
\ref{chap:experimental-setup} is Sun Hotspot JDK 1.6. In both cases,
the JVM was invoked with the following parameters:

\begin{verbatim}
    -server -Xmx2048M -Xms2048M -Xss8m
\end{verbatim}

\subsection*{Crypt}

Crypt performs IDEA (International Data Encryption Algorithm)
encryption and decryption of an array of $N$ bytes. This algorithm
involves two principle loops, whose iterations are independent and are
divided using fork-join sections between \emph{intervals} in a block fashion.

\subsection*{LUFact}

This benchmark solves an $N \times N$ linear system using LU factorization
followed by a triangular solve. Iterations of the double loop over the
trailing block of the matrix are independent and the work is divided
between \emph{intervals} in a cyclic fashion using fork-join sections.

\subsection*{SOR}

The benchmark performs iterations of successive over-relaxations on a
$N \times N$ grid. It involves an outer loop over iterations and two
inner loops, each looping over the grid. In order to parallelize the
loop over array rows, a ``red-black'' ordering mechanism is used. The
work is distributed between \emph{intervals} in a block manner with
help of point-to-point synchronization.

\subsection*{Series}

This benchmark computes the first $N$ fourier coefficients of the
function $f(x) = (x+1)^x$ on the interval $0,2$. It uses fork-join
sections to distribute the loop over the Fourier coefficients between
\emph{intervals}.

\subsection*{MolDyn}

The MolDyn benchmark models particles interacting under a
Lennard-Jones potential in a cubic spatial volume with periodic
boundary conditions. The calculation is distributed between
\emph{intervals} in a cyclic manner and synchronization is done using
barriers.

\subsection*{MonteCarlo}

This benchmark is a financial simulation, using Monte Carlo techniques
to price products derived from the price of an underlying asset. The
work is divided between \emph{intervals} by using fork-join sections.

\subsection*{RayTracer}

This benchmark measures the performance of a 3D ray tracer rendering a
scene containing 64 spheres at a resolution of $N \times N$
pixels. The loop over rows of pixels has been distributed to
\emph{intervals} using fork-join sections.


\section{Locality-aware Benchmarks}

We evaluate the locality-aware implementation of \emph{intervals} on a
variety of benchmarks. To reduce the impact of JVM overheads in the
evaluation, including JIT compilation and garbage collection, the
execution time reported is the average of the three best benchmark
iterations from three seperate VM incocations. Each VM invocation
performs 10 benchmark iterations.

The JVM used on both machines described in appendix
\ref{chap:experimental-setup} is Sun Hotspot JDK 1.6. In both cases,
the JVM was invoked with the following parameters:

\begin{verbatim}
    -server -Xmx4096M -Xms4096M -Xss8m -XX:+UseNUMA
\end{verbatim}

\verb!-XX:+UseNUMA! turns on the NUMA-aware allocator in conjunction
with the selection of the Parallel Scavenger garbage collector
\cite{Oracle2010} \cite{Humble2010}. The allocator controls the eden
space of the young generation of the heap, where most of the new
objects are created. The allocator divides the space into regions each
of which is placed in the memory of a specific node. The allocator
relies on a hypothesis that a thread that allocates the object will be
the most likely to use the object. To ensure the fastest access to the
new object, the allocator places it in the region local to the
allocating thread. The regions can be dynamically resized to reflect
the allocation rate of the application threads running on different
nodes. That makes it possible to increase performance even of
single-threaded applications. In addition, ``from'' and ``to''
survivor spaces of the young generation, the old generation, and the
permanent generation have page interleaving turned on for them. This
ensures that all threads have equal access latencies to these spaces
on average.

The following benchmarks were first written to use threads and then
ported over to use \emph{intervals}.

\subsection*{Cache-stress Test}

TODO: Describe benchmark

\subsection*{Cache-efficient Test}

TODO: Should this benchmark really be included?

\subsection*{Merge Sort}

TODO: Describe benchmark

\subsection*{Block Matrix Multiplication}

TODO: Describe benchmark


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 