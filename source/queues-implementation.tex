%==============================================================================
% queues-implementation.tex
%==============================================================================

\chapter{Investigated Queues}
\label{chap:queues-implementation}

% We present three algorithms, each with a different choice for how the
% items are extracted. In all of our algorithms, the owner inserts new
% tasks at the tail of the queue. In the first algorithm (idempotent
% LIFO) tasks are always extracted from the tail, while in the second
% algorithm (idempotent FIFO) tasks are always extracted from the
% head. In the third algorithm (idempotent double-ended), the owner
% extracts from the tail while thieves extract from the head of the
% queue. We use the term queue loosely to mean a structure with items
% stored in the order in which they were inserted.

\section{Work-Stealing Deque}
\label{sec:queues-implementation-ws-deque}

The \emph{Work-Stealing Deque} is an unbounded double-ended queue that
dynamically resizes itself as needed. Its design is based on the
\emph{Dynamic Circular Work-Stealing Deque} \cite{Chase2005, Lev2005}.

The \lstinline!WorkStealingDeque! class has three fields,
\lstinline!workItems!, \lstinline!bottom!, and \lstinline!top!:

\lstinputlisting[style=Listing, nolol,]
%  caption={Work-stealing deque}, 
%  label=lst:work-stealing-deque,]
{
    ../listings/queues-implementation/WorkStealingDeque.java
}

The array \lstinline!workItems! is used in a cyclic way with
\lstinline!top! and \lstinline!bottom! indicating the two ends of the
deque. An important property of \lstinline!top! is that it is never
decreased. If \lstinline!bottom! is less than or equal to
\lstinline!top!, the deque is empty.

The \lstinline!put()! method (Listing
\ref{lst:work-stealing-deque-put}) first checks whether the current
circular array is full (Line
\ref{lst:work-stealing-deque-put-size}). If it is full, we call
\lstinline!expand()! (Line \ref{lst:work-stealing-deque-put-expand})
to enlarge it by copying the deque's elements into a bigger array. Now
we can put the new work item in the location specified by
\lstinline!bottom!, and then increment \lstinline!bottom! by 1 (Line
\ref{lst:work-stealing-deque-put-update-bottom}).

\lstinputlisting[style=Numbers,
  caption={Work-stealing deque: \lstinline!put()! method}, 
  label=lst:work-stealing-deque-put]{
    ../listings/queues-implementation/WorkStealingDeque-put.java
}

Listing \ref{lst:work-stealing-deque-expand} shows the
\lstinline!expand()! method. It allocates a new doubled size array and
copies the old array's elements into the new array. The use of modular
arithmetic ensures that even though the array has changed size and the
work items may have shifted positions, there is no need to update the
\lstinline!top! or \lstinline!bottom! fields.

\lstinputlisting[style=Numbers,
  caption={Work-stealing deque: \lstinline!expand()! method}, 
  label=lst:work-stealing-deque-expand]{
    ../listings/queues-implementation/WorkStealingDeque-expand.java
}

In Listing \ref{lst:work-stealing-deque-take} we define the
\lstinline!take()! method. If the deque is empty, we reset it to an
empty state where \lstinline!bottom == top! and return
\lstinline!null! (Lines \ref{lst:work-stealing-deque-take-empty-1} --
\ref{lst:work-stealing-deque-take-empty-2}). If taking a work item
does not make the deque empty, the owner can take it without using a
Compare-and-Swap operation (Lines
\ref{lst:work-stealing-deque-take-non-empty-1} --
\ref{lst:work-stealing-deque-take-non-empty-2}). If the owner is
trying to take the last work item, then it must perform a
Compare-and-Swap on \lstinline!top! to see if it won or lost any race
with a concurrent \lstinline!steal()! operation to take the last item
(Line \ref{lst:work-stealing-deque-take-cas}). Regardless whether the
Compare-and-Swap operation succeeds, the value of \lstinline!top! is
incremented by 1 and the deque is empty: If the Compare-and-Swap in
\lstinline!take()! fails, then some concurrent \lstinline!steal()!
operation succeeded in stealing the last work item and incremented
\lstinline!top!. Therefore the operation completes by storing the
incremented top value in \lstinline!bottom! which resets the deque to
an empty state (Line \ref{lst:work-stealing-deque-take-update}).

\lstinputlisting[style=FloatNumbers,
  caption={Work-stealing deque: \lstinline!take()! method},
  label=lst:work-stealing-deque-take]{
    ../listings/queues-implementation/WorkStealingDeque-take.java
}

The \lstinline!steal()! method (Listing
\ref{lst:work-stealing-deque-steal}) first reads \lstinline!top!, then
\lstinline!bottom!. The order is important: If a thread reads
\lstinline!bottom! after \lstinline!top! and sees it is no greater,
the queue is indeed empty because a concurrent modification of
\lstinline!top! could only have increased the \lstinline!top! value.

If the deque is empty, \lstinline!steal()! returns \lstinline!null!
(Lines \ref{lst:work-stealing-deque-steal-empty-1} --
\ref{lst:work-stealing-deque-steal-empty-2}). Else it reads the
element stored in the \lstinline!top! position of the cyclic array,
and tries to increment \lstinline!top! using a Compare-and-Swap
operation. If the Compare-and-Swap fails, it implies that a concurrent
\lstinline!steal()! successfully removed an element from the deque, so
the operation tries to steal again. Otherwise it returns the element
read right before the successful Compare-and-Swap operation.

To prevent \lstinline!steal()! from returning the deque's last work
item if it was already taken by a concurrent \lstinline!take()! after
\lstinline!bottom! is read (Line
\ref{lst:work-stealing-deque-steal-bottom}), but before the
Compare-and-Swap operation is executed (Line
\ref{lst:work-stealing-deque-steal-cas}), any \lstinline!take()! that
empties the deque tries to modify \lstinline!top! using a
Compare-and-Swap operation.

\lstinputlisting[style=FloatNumbers,
  caption={Work-stealing deque: \lstinline!steal()! method}, 
  label=lst:work-stealing-deque-steal]{
    ../listings/queues-implementation/WorkStealingDeque-steal.java
}

\section{Idempotent Work-Stealing Deque}
\label{sec:queues-implementation-idempotent-ws-deque}

The \emph{Idempotent Work-Stealing Deque} is based on ideas from
\cite{Leijen2009} and \cite{Michael2009}. It is an unbounded
double-ended queue that can resize itself if needed.

Unlike the \emph{Lazy Deque} (Section
\ref{sec:queues-background-current-implementation}) or the
\emph{Work-Stealing Deque} (Section
\ref{sec:queues-implementation-ws-deque}), the \emph{Idempotent
Work-Stealing Deque} does not guarantee that each inserted work item
is extracted \emph{exactly} once. Instead it uses the relaxed
semantics of guaranteeing that each inserted work item is extracted
\emph{at least} once.

While this nondeterminism might be dangerous in many applications, it
is fine for our usage of the deque as we modified the interval's
\lstinline!exec()! method to be idempotent (see Section
\ref{sec:queues-implementation-idempotent-ws-deque-interval}).\footnote{If
the application can tolerate duplicated work, for example parallel
garbage collectors or constraint solvers, we do not have to make the
\verb!exec()! method idempotent.}

\subsection{Idempotent Interval}
\label{sec:queues-implementation-idempotent-ws-deque-interval}

Listing \ref{lst:interval} shows the idempotent interval
implementation. Each interval has an associated state
\lstinline!RunningState! (Line \ref{lst:interval-state}). Upon
initialization, the state is set to \lstinline!INIT! (Line
\ref{lst:interval-init}). The internal \lstinline!exec()!  method
performs an atomic Compare-and-Swap operation to try to switch from
\lstinline!INIT! to \lstinline!RUNNING! (Line
\ref{lst:interval-cas}). If the Compare-and-Swap operation succeeds,
the associated task is executed and the state is set to
\lstinline!DONE! afterwards (Line \ref{lst:interval-done}).

\lstinputlisting[style=Numbers, 
  caption={Idempotent interval},
  label=lst:interval]{ 
    ../listings/queues-implementation/Interval.java 
}

This ensures that each interval is only executed once, or stated
differently: running an interval is an idempotent operation.

Idempotent intervals would also simplify the mailbox style
implementation for locality-aware scheduling \cite{Acar2002}.

\subsection{Implementation}
\label{sec:queues-implementation-idempotent-ws-deque-implementation}

In contrast to the \emph{Lazy Deque} (Section
\ref{sec:queues-background-current-implementation}) or the
\emph{Work-Stealing Deque} (Section
\ref{sec:queues-implementation-ws-deque}), the owner's methods
\lstinline!put()! and \lstinline!take()! of the \emph{Idempotent
Work-Stealing Deque} do not have to use expensive Compare-and-Swap
operations. We can optimize the owner's methods by avoiding the high
overheads of these operations.

The \lstinline!IdempotentWorkStealingDeque! class has an inner class,
\lstinline!ArrayData!, and two fields, \lstinline!anchor! and
\lstinline!workItems!:

\lstinputlisting[style=Listing, nolol,]
%  caption={Idempotent work-stealing deque}, 
%  label=lst:idempotent-work-stealing-deque]
{
    ../listings/queues-implementation/IdempotentWorkStealingDeque.java
}

The array \lstinline!workItems! is used in a cyclic way with head and
size encapsulated in an \lstinline!ArrayData! reference. The
\lstinline!ArrayData! reference is maintained by the atomic stamped
reference \lstinline!anchor! together with an integer stamp. Our
algorithm needs to guard against the ABA problem\footnote{If a thread
  reads a value $A$ from a shared variable, computes a new value, and
  then attempts a Compare-and-Swap operation, there is a chance that
  the Compare-and-Swap succeeds even if it should not, because for
  example between the read and the Compare-and-Swap some other thread
  changes the $A$ back to $B$ and then back to $A$ again.} in the
\lstinline!steal()! operation and uses the stamp as an ABA-prevention
tag.\footnote{The tag is a specific implementation choice. At the
  abstract level, the algorithms do not require the use of the tag
  mechanism but can use any ABA prevention mechanism, like bounded
  tags \cite{Moir1997} or hazard pointers \cite{Michael2004}}

Listing \ref{lst:idempotent-work-stealing-deque-put} shows the
\lstinline!put()! method. First the owner reads the anchor to get the
head and size of the queue as well as the ABA-prevention tag (Lines
\ref{lst:idempotent-work-stealing-deque-put-read-1} --
\ref{lst:idempotent-work-stealing-deque-put-read-2}). Then the owner
checks whether the array is full of not (Line
\ref{lst:idempotent-work-stealing-deque-put-full}). If it is full, the
owner expands the array by calling \lstinline!expand()! and loops
around (Line
\ref{lst:idempotent-work-stealing-deque-put-expand}). Otherwise, it
adds the work item at the tail of the queue (Line
\ref{lst:idempotent-work-stealing-deque-put-insert}). In Line
\ref{lst:idempotent-work-stealing-deque-put-update-anchor} the owner
updates the anchor by incrementing the queues size and ABA-prevention
tag.

\lstinputlisting[style=FloatNumbers,
  caption={Idempotent work-stealing deque: \lstinline!put()! method},
  label=lst:idempotent-work-stealing-deque-put]{
    ../listings/queues-implementation/IdempotentWorkStealingDeque-put.java
}

The method \lstinline!expand()! is defined in Listing
\ref{lst:idempotent-work-stealing-deque-expand}. For the owner to
expand a full queue, it allocates a new array with double the current
capacity (Line
\ref{lst:idempotent-work-stealing-deque-expand-new-array}) and copies
the work items from the current array to the newly allocated one
(Lines \ref{lst:idempotent-work-stealing-deque-expand-copy-1} --
\ref{lst:idempotent-work-stealing-deque-expand-copy-2}). After that,
it sets \lstinline!workItems! to the new array (Line
\ref{lst:idempotent-work-stealing-deque-expand-assign}).

\lstinputlisting[style=FloatNumbers,
  caption={Idempotent work-stealing deque: \lstinline!expand()! method},
  label=lst:idempotent-work-stealing-deque-expand]{
    ../listings/queues-implementation/IdempotentWorkStealingDeque-expand.java
}

Listing \ref{lst:idempotent-work-stealing-deque-take} defines the
method \lstinline!take()!. The owner reads the anchor variable to get
the head and size of the queue, and also the ABA-prevention tag (Lines
\ref{lst:idempotent-work-stealing-deque-take-read-anchor-1} --
\ref{lst:idempotent-work-stealing-deque-take-read-anchor-2}). Then it
checks if the queue is empty (Line
\ref{lst:idempotent-work-stealing-deque-take-check-size}). If it is
empty, \lstinline!take()! return \lstinline!null!. Otherwise, it reads
the work item at the tail of the queue (Lines
\ref{lst:idempotent-work-stealing-deque-take-get}). In Line
\ref{lst:idempotent-work-stealing-deque-put-update-anchor} the method
updates the anchor by decrementing the queues size to indicate the
extraction of a work item.

\lstinputlisting[style=FloatNumbers,
  caption={Idempotent work-stealing deque: \lstinline!take()! method},
  label=lst:idempotent-work-stealing-deque-take]{
    ../listings/queues-implementation/IdempotentWorkStealingDeque-take.java
}


The \lstinline!steal()! method (Listing
\ref{lst:idempotent-work-stealing-deque-steal}) starts by reading the
anchor variable to get the head and size of the queue as well as the
ABA-prevention tag (Lines
\ref{lst:idempotent-work-stealing-deque-steal-read-anchor-1} --
\ref{lst:idempotent-work-stealing-deque-steal-read-anchor-2}). In Line
\ref{lst:idempotent-work-stealing-deque-steal-check-size} the thread
checks if the queue is empty. If it is empty, \lstinline!steal()!
returns \lstinline!null!. Otherwise it gets a pointer to
\lstinline!workItems!. In Line
\ref{lst:idempotent-work-stealing-deque-steal-read}, the thread reads
the work item at the head of the queue.

The \lstinline!compareAndSet()! in Line
\ref{lst:idempotent-work-stealing-steal-cas} checks that no work item
was lost: Checking of the ABA-prevention tag makes sure that since the
reads in Lines
\ref{lst:idempotent-work-stealing-deque-steal-read-anchor-1} --
\ref{lst:idempotent-work-stealing-deque-steal-read-anchor-2} the deque
owner has not overwritten the work item read in Line
\ref{lst:idempotent-work-stealing-deque-steal-read}. If the
\lstinline!compareAndSet()! is successful, it updates the anchor with
the incremented head and decremented size to indicate the stealing and
returns the stolen work item. Else, the thread tries to steal again.

\lstinputlisting[style=FloatNumbers,
  caption={Idempotent work-stealing deque: \lstinline!steal()! method},
  label=lst:idempotent-work-stealing-deque-steal]{
    ../listings/queues-implementation/IdempotentWorkStealingDeque-steal.java
}


\section{Alternative Implementations}
\label{sec:queues-alternative-implementations}

Besides the \emph{Work-Stealing Deque} and \emph{Idempotent
  Work-Stealing Deque} we also implemented the alternative
work-stealing queues \emph{Dynamic Work-Stealing Deque} (Section
\ref{sec:queues-alternative-implementations-dynamic-deque}) and
\emph{Duplicating Work-Stealing Queue} (Section
\ref{sec:queues-alternative-implementations-duplicating-queue}).

\subsection{Dynamic Work-Stealing Deque}
\label{sec:queues-alternative-implementations-dynamic-deque}

The list-based work-stealing deque algorithm presented by Hendler, Lev
and Shavit \cite{Hendler2006, Hendler2006a} uses a list of small
arrays to eliminate the overflow problem. However, it is relatively
complicated, does not use cyclic arrays (and therefore wastes some
memory), and introduces a trade-off between its time and space
complexity due to the extra work required for the list's maintenance.

\subsubsection{The new algorithm}

This paper introduces the first lock-free\footnote{Our abstract deque
  definition is such that the original ABP algorithm is also
  lock-free.} dynamic-sized version of the ABP work-stealing
algorithm. It provides a near-optimal memory-size/robustness tradeoff:
for n processes and total pre-allocated memory size m, it can
potentially tolerate up to $O(m)$ items in a single deque. It also
allows one to malloc additional memory beyond m when needed, and as
our empirical data shows, it is far more robust than the array-based
ABP algorithm in multiprogrammed environments.

An ABP-style work stealing algorithm consists of a collection of deque
data structures with each process performing pushes and pops on the
\emph{bottom} end of its local deque and multiple thieves performing pops
on the \emph{top} end. The new algorithm implements each deque as a
doubly linked list of nodes, each of which is a short array that is
dynamically allocated from and freed to a shared pool; see Fig. 1. It
can also use malloc to add nodes to the shared pool in case its node
supply is exhausted.

The main technical difficulties in the design of the new algorithm
arise from the need to provide performance comparable to that of
ABP. This means the doubly linked list must be manipulated using only
loads and stores in the common case, resorting to using a costly CAS
only when a potential conflict requires it; it is challenging to make
this transition correctly while maintaining lock-freedom.

The potential conflict that requires CAS-based synchronization occurs
when a pop by a local process and a pop by a thief might both be
trying to remove the same item from the deque. The original ABP
algorithm detects this scenario by examining the gap between the
\lstinline!Top! and \lstinline!Bottom! array indices, and uses a CAS
operation only when they are \emph{too close}. Moreover, in the original
algorithm, the empty deque scenario is checked simply by checking
whether \lstinline!Bottom $\le$ Top!.

A key algorithmic feature of our new algorithm is the creation of an
equivalent mechanism to allow detection of these boundary situations
in our linked list structures using the relations between the
\lstinline!Top! and \lstinline!Bottom! pointers, even though these
point to entries that may reside in different nodes. On a high level,
our idea is to prove that one can restrict the number of possible ways
the pointers interact, and therefore, given one pointer, it is
possible to calculate the different possible positions for the other
pointer that imply such a boundary scenario.

The other key feature of our algorithm is that the dynamic insertion
and deletion operations of nodes into the doubly linked-list (when
needed in a push or pop) are performed in such a way that the local
thread uses only loads and stores. This contrasts with the more
general linked-list deque implementations [11, 12] which require a
double-compare-and-swap synchronization operation [13] to insert and
delete nodes.

\subsubsection{Description}

Figure 1b presents our new deque data-structure. The doubly-linked
list's nodes are allocated from and freed to a shared pool, and the
only case in which one may need to malloc additional storage is if the
shared pool is exhausted. The deque supports the
\lstinline!PushBottom! and \lstinline!PopBottom! operations for the
local process, and the \lstinline!PopTop! operation for the thieves.

The first technical difficulty we encountered is in detecting the
conflict that may arise when the local \lstinline!PopBottom! and a
thief's \lstinline!PopTop! operations concurrently try to remove the
last item from the deque. Our solution is based on the observation
that when the deque is empty, one can restrict the number of possible
scenarios among the pointers. Given one pointer, we show that the
\emph{virtual} distance of the other, ignoring which array it resides in,
cannot be more than 1 if the deque is empty. We can thus easily test
for each of these scenarios. (Several such scenarios are depicted in
parts (a) and (b) of Fig. 2).

The next problem one faces is the maintenance of the deque's
doubly-linked list structure. We wish to avoid using CAS operations
when updating the next and previous pointers, since this would cause a
significant performance penalty. Our solution is to allow only the
local process to update these fields, thus preventing
\lstinline!PopTop! operations from doing so when moving from one node
to another. We would like to keep the deque dynamic, which means
freeing old nodes when they're not needed anymore. This restriction
immediately implies that an active list node may point to an already
freed node, or even to a node which was freed and reallocated again,
essentially ruining the list structure. As we prove, the algorithm can
overcome this problem by having a \lstinline!PopTop! operation that
moves to a new node free only the node preceding the old node and not
the old node itself. This allows us to maintain the invariant that the
doubly-linked list structure between the \lstinline!Top! and
\lstinline!Bottom! pointers is preserved. This is true even in
scenarios such as that depicted in parts b and c of Fig. 2 where the
pointers cross over.

\subsubsection{Implementation}

C++-like pseudocode for our deque algorithm is given in Figs. 3 --
5. As depicted in Fig. 3, the deque object stores the
\lstinline!Bottom! and \lstinline!Top! pointers information in the
\lstinline!Bottom! and \lstinline!Top! data members. This information
includes the pointer to a list's node and an offset into that node's
array. For the \lstinline!Top! variable, it also includes a tag value
to prevent the ABA problem \cite{Dechev2006}. The deque methods uses
the \lstinline!EncodeBottom!, \lstinline!DecodeBottom!,
\lstinline!EncodeTop! and \lstinline!DecodeTop! macros to
encode/decode this information to/from a value that fits in a CAS-able
size word.\footnote{If the architecture does not support a 64-bit CAS
  operation, we may not have the space to save the whole node
  pointer. In this case, we might use the offset of the node from some
  base address given by the shared memory pool. For example, if the
  nodes are allocated continuously, the address of the first node can
  be such a base address.} Underlined procedures in the pseudocode
represent code blocks which are presented in the detailed algorithm
presentation used for the correctness proof in Sect. 4. We now
describe each of the methods.

\minisec{PushBottom}

The \lstinline!PushBottom! method begins by reading \lstinline!Bottom!
and storing the pushed value in the cell it's pointing to (Lines
1 -- 2). Then it calculates the next value of \lstinline!Bottom! linking
a new node to the list if necessary (Lines 3 -- 14). Finally the method
updates \lstinline!Bottom! to its new value (Line 15). As in the
original ABP algorithm, this method is executed only by the owner
process, and therefore regular writes suffice (both for the value and
\lstinline!Bottom! updates). Note that the new node is linked to the
list before \lstinline!Bottom! is updated, so the list structure is
preserved for the nodes between \lstinline!Bottom! and
\lstinline!Top!.

\minisec{PopTop}

The \lstinline!PopTop! method begins by reading the \lstinline!Top!
and \lstinline!Bottom! values, in that order (Lines 16 -- 18). Then it
tests whether these values indicate an empty deque, and returns
\lstinline!EMPTY! if they do\footnote{This test may also return
  \lstinline!ABORT! if \lstinline!Top! was modified, since then it is
  not guaranteed that the tested values represent a consistent view of
  the memory.} (Line 19). Otherwise, it calculates the next position
for \lstinline!Top! (Lines 20 -- 31). Before updating \lstinline!Top! to
its new value, the method must read the value which should be returned
if the steal succeeds (Line 32) (this read cannot be done after the
update of \lstinline!Top! because by then the node may already be
freed by some other concurrent \lstinline!PopTop! execution). Finally
the method tries to update \lstinline!Top! to its new value using a
CAS operation (Line 34), returning the popped value if it succeeds, or
\lstinline!ABORT! if it fails. (In the work stealing algorithm, if a
thief process encounters contention with another, it may be preferable
to try stealing from a different deque; returning \lstinline!ABORT! in
this case provides the opportunity for the system to decide between
retrying on the same deque or doing something different.) If the CAS
succeeds, the method also checks whether there is an old node that
needs to be freed (Line 36). As explained earlier, a node is released
only if \lstinline!Top! moved to a new node, and the node released is
not the old top node, but the preceding one.

\minisec{PopBottom}

The \lstinline!PopBottom! method begins by reading \lstinline!Bottom!
and updating it to its new value (Lines 43 -- 55) after reading the value
to be popped (Line 54). Then it reads the value of \lstinline!Top!
(Line 56), to check for the special cases of popping the last entry of
the deque, and popping from an empty deque. If the \lstinline!Top!
value read points to the old \lstinline!Bottom! position (Lines 58 -- 
63), then the method rewrites \lstinline!Bottom! to its old position,
and returns \lstinline!EMPTY! (since the deque was empty even without
this \lstinline!PopBottom! operation). Otherwise, if \lstinline!Top!
is pointing to the new \lstinline!Bottom! position (Lines 64 -- 78), then
the popped entry was the last in the deque, and as in the original ABP
algorithm, the method updates the \lstinline!Top! tag value using a
CAS, to prevent a concurrent \lstinline!PopTop! operation from
popping out the same entry. Otherwise there was at least one entry in
the deque after the \lstinline!Bottom! update (lines 79 -- 83), in which
case the popped entry is returned. Note that, as in the original ABP
algorithm, most executions of the method will be short, and will not
involve any CAS-based synchronization operations.

\subsection{Duplicating Work-Stealing Queue}
\label{sec:queues-alternative-implementations-duplicating-queue}

The \emph{Duplicating Work-Stealing Queue} provides an alternative to
the \emph{Idempotent Work-Stealing Deque}. Its design is based on the
Task Parallel Library (TPL) \cite{Leijen2009}.

Unlike the \emph{Lazy Deque} (Section
\ref{sec:queues-background-current-implementation}) or the
\emph{Work-Stealing Deque} (Section
\ref{sec:queues-implementation-ws-deque}), the \emph{Idempotent
  Work-Stealing Deque} does not guarantee that each inserted work item
is extracted \emph{exactly} once. Instead it uses the relaxed
semantics of guaranteeing that each inserted work item is extracted
\emph{at least} once.

While this nondeterminism might be dangerous in many applications, it
is fine for our usage of the deque as we modified the interval's
\lstinline!exec()! method to be idempotent (see Section
\ref{sec:queues-implementation-idempotent-ws-deque-interval}).\footnote{If
  the application can tolerate duplicated work, for example parallel
  garbage collectors or constraint solvers, we do not have to make the
  \verb!exec()! method idempotent.}

\subsection{Idempotent Interval}

Listing \ref{lst:interval} shows the idempotent interval
implementation. Each interval has an associated state
\lstinline!RunningState! (Line \ref{lst:interval-state}). Upon
initialization, the state is set to \lstinline!INIT! (Line
\ref{lst:interval-init}). The internal \lstinline!exec()!  method
performs an atomic Compare-and-Swap operation to try to switch from
\lstinline!INIT! to \lstinline!RUNNING! (Line
\ref{lst:interval-cas}). If the Compare-and-Swap operation succeeds,
the associated task is executed and the state is set to
\lstinline!DONE! afterwards (Line \ref{lst:interval-done}).

This ensures that each interval is only executed once, or stated
differently: running an interval is an idempotent operation.

Idempotent intervals would also simplify the mailbox style
implementation for locality-aware scheduling \cite{Acar2002}.

\subsection{Implementation}

In contrast to the \emph{Lazy Deque} (Section
\ref{sec:queues-background-current-implementation}) or the
\emph{Work-Stealing Deque} (Section
\ref{sec:queues-implementation-ws-deque}), the owner's methods
\lstinline!put()! and \lstinline!take()! of the \emph{Idempotent
  Work-Stealing Deque} do not have to use expensive Compare-and-Swap
operations. We can optimize the owner's methods by avoiding the high
overheads of these operations.

Of course, exploiting weak memory models is playing with fire. That's
why we verified the correctness of the duplicating queue formally
using the Checkfence tool \cite{Burckhardt2007, Burckhardt2007a}.

\subsubsection{Duplicating Queues}

A duplicating queue is a double-ended queue that potentially returns a
pushed element more than once. In particular, the \lstinline!put()!
and \lstinline!take()! operations behave like normal, but the
\lstinline!steal()! operation is allowed to either take an element
(and remove it from the queue), or to just duplicate an element in the
queue. While this nondeterminism might be dangerous for many clients,
it is fine for our usage of the duplicating queue: the Task's Run
method is idempotent and ReplicableTask's expect to be executed in
parallel. Other properties of a duplicating queues are as usual: a
duplicating queue never loses an element, and returns all pushed
elements after a finite number of \lstinline!take()! (and
\lstinline!steal()!) operations.

By allowing duplication we can avoid an expensive memory barrier
instruction in the \lstinline!take()! operation on the x86
architecture. More generally, our duplicating queue is designed
specifically to be correct on architectures satisfying the Total Store
Order (TSO) memory model (Sindhu et al. 1991) or stronger model. To
our knowledge, this is one of the first data structures that takes
specific advantage of weaker memory models to avoid memory
barriers. An interesting aspect is that the non-determinism that is
introduced by the weaker memory model is captured in a benign way
where the number of duplicated elements is non-deterministically
determined.

\subsubsection{Related Work}

There is a wealth of research into parallel scheduling algorithms,
data structures, and language designs, and we necessarily restrict
this section to work that is directly relevant to work stealing and
embedded library designs.

The idea of duplicating queues has recently been described as
\emph{idempotent} queues \cite{Michael2009}. We were not aware of this
work at the time of writing this paper and arrived at our results
independently (doing our first implementation in January 2008). Their
general motivation and the semantics of the idempotent queue seem
largely identical, but the implementation is quite different. Their
elegant implementation packs fields together in a memory word and
relies strictly on atomic compare-and-swap and memory ordering
instructions. In contrast, our implementation uses a simple lock on
all but the critical paths which can simplify many implementation
aspects and also removes a level of indirection on the critical path.

\todo{Finish section \emph{Alternative Implementations}}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
