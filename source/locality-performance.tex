%==============================================================================
% locality-performance.tex
%==============================================================================

\chapter{Performance Evaluation}
\label{chap:locality-performance}

\section{Methodology}
\label{sec:locality-performance-methodology}

The performance results in this chapter are obtained on an Intel
Nehalem system with 2 processors and 8 cores, running Ubuntu 9.04
64-bit with kernel 2.6.29 patched to support perfmon2
\cite{Eranian2008} (Appendix
\ref{sec:experimental-setup-mafushi}). The JVM used is Sun Hotspot JDK
1.6.0\_20 which is invoked with the following parameters:

\begin{lstlisting}[style=Listing]
  -server -Xmx4096M -Xms4096M -Xss8M -XX:+UseNUMA
\end{lstlisting}

Besides the runtime of the benchmarks, we are mostly interested in the
count of cache hits and miss events. Since the last level cache is
part of the uncore, we have to use the uncore PMU to count L3 cache
events. We use perfmon2 to track the following events
\cite{Levinthal2009}:

\begin{itemize}
\item \lstinline!UNC_LLC_HITS.READ!: Number of L3 cache read hits
\item \lstinline!UNC_LLC_MISS.READ!: Number of L3 cache read misses
% Other counters?
\end{itemize}

The execution time reported is the average of the 3 best benchmark
iterations from 10 separate invocations. The cache events count
presented is that of the best benchmark execution from the same 10
invocations used to get the runtime.


\section{Non-Locality Benchmarks}
\label{sec:locality-performance-non-locality}

It is important that our new scheduler implementation does not affect
the performance of existing locality-ignorant intervals
applications. Thus, we run the locality-ignorant JGF benchmarks
(Appendix \ref{chap:benchmarks}) with our new scheduler
implementation. As Figure \ref{fig:locality-performance-jgf} shows,
the performance of the locality-ignorant JGF benchmarks run with the
locality-aware intervals scheduler is comparable to the original
implementation.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.8\linewidth]{locality-performance/mafushi-jgf}
  \caption[Locality-ignorant JGF benchmarks running on locality-aware
  scheduler]{Locality-ignorant JGF benchmarks using the locality-aware
    scheduler on our Intel Nehalem (Appendix
    \ref{sec:experimental-setup-mafushi}) test machine}
  \label{fig:locality-performance-jgf}
\end{figure}


\section{Locality Benchmarks}
\label{sec:locality-performance-locality}

\subsection{Cache-Stress Test}
\label{sec:locality-performance-cache-stress-test}

We ported the \emph{Cache Stress Test} benchmark from the threaded
version developed in Chapter \ref{chap:locality-approach} to use
intervals.

Like the threaded version, it first randomly initializes two integer
arrays of equal size as the last level cache per processor. Then it
creates an inline root interval which produces 64 subintervals with
their locality set to a specific place: 32 have their locality set for
\emph{place 0} and 32 for \emph{place 1}.

One half of the subintervals operate on the elements of the first
array and the other half operate on the elements of the second
array. Each interval's task adds and multiplies all the elements of
its respective array 100 times.

Like in the threaded version, we implement several different variants
of the benchmark, each having different locality properties:

\begin{description}
\item[Best Locality:] All the intervals working on the first array
  have their locality set to \emph{place 0} and all intervals working
  on the second array have their locality set to \emph{place 1}.
\item[Ignorant Locality:] The intervals do not have any locality set,
  i.e. they are locality-ignorant.
\item[Random Locality:] The locality of the intervals is set to a
  \emph{random} place.
\item[Worst Locality:] Half the intervals with locality for
  \emph{place 0} work on the first array, and the other half works on
  the second array and vice versa for the intervals with locality for
  \emph{place 1}.
\end{description}

Figure \ref{fig:locality-performance-cache-stress-test-mafushi} shows
the place allocations for the benchmark variants with \emph{best} and
\emph{worst locality}.

\begin{figure}[!ht]
  \centering
  \subfloat[Best Locality]{
    \includegraphics[width=0.5\linewidth]{locality-performance/cache-stress-test-mafushi-best}
    \label{fig:locality-performance-cache-stress-mafushi-best}
  }
  \subfloat[Worst Locality]{
    \includegraphics[width=0.5\linewidth]{locality-performance/cache-stress-test-mafushi-worst}
    \label{fig:locality-performance-cache-stress-mafushi-worst}
  }
  \caption{\emph{Cache Stress Test} with \emph{best} and \emph{worst
      locality}}
  \label{fig:locality-performance-cache-stress-test-mafushi}
\end{figure}

When running the intervals implementations of the \emph{Cache Stress
  Test} benchmarks, we observe similar behavior to the threaded
versions. As is shown in Table
\ref{tab:locality-performance-cache-stress-test} the implementation
with \emph{best locality} is the fastest and provides the largest
speedup.

\begin{table}[htb]
  \centering
  \begin{tabular}{ln{2}{3}n{1}{2}}
    \toprule
    & {Runtime (in seconds)} & {Speedup (over sequential)} \\\midrule
    \emph{Best Locality} & 3.596 & 7.11 \\
    \emph{Ignorant Locality} & 4.038 & 6.33 \\
    \emph{Random Locality} & 4.030 & 6.35 \\
    \emph{Worst Locality} & 3.982 & 6.42 \\
    \emph{Sequential Implementation}\hspace{0.5cm} & 25.571 & 1 \\\bottomrule
  \end{tabular}
  \caption{\emph{Cache Stress Test} execution times and speedups over sequential implementation}
  \label{tab:locality-performance-cache-stress-test}
\end{table}

In Figure \ref{fig:locality-performance-cache-stress-test} we show the
execution times normalized to that of the \emph{best locality}
implementation. The \emph{best locality} implementation is more than
10\% faster compared to the other locality benchmarks.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.8\linewidth]{locality-performance/cache-stress-test}
  \caption{\emph{Cache Stress Test} with execution times normalized to
    \emph{best locality}}
  \label{fig:locality-performance-cache-stress-test}
\end{figure}

In the \emph{best locality} benchmark, the intervals perform
prefetching of the array elements for one another. In the other
benchmarks, intervals compete for the L3 cache and overwrite one
another's entries. This reflects itself in the number of cache hit and
miss events listed in Table
\ref{tab:locality-performance-cache-stress-test-cache-hits-misses}.

\begin{table}[htb]
  \centering
  \begin{tabular}{ln{4}{0}n{4}{0}}
    \toprule
    & {L3 Cache Read Hits}  & {L3 Cache Read Misses} \\\midrule
    \emph{Best Locality}\hspace{1cm} & 2335 & 275 \\
    \emph{Ignorant Locality} & 1568 & 837 \\
    \emph{Random Locality} & 1570 & 854 \\
    \emph{Worst Locality} & 1539 & 837 \\\bottomrule
  \end{tabular}
  \caption[\emph{Cache Stress Test} L3 cache read hits and misses]
  {\emph{Cache Stress Test} L3 cache read hits and misses (rounded to the nearest million)}
  \label{tab:locality-performance-cache-stress-test-cache-hits-misses}
\end{table}

Figure \ref{fig:locality-performance-cache-stress-test} shows the
cache hits and misses normalized to the measurements of the \emph{best
  locality} implementation. The \emph{best locality} benchmark has up
to 1.5\texttimes\ more L3 cache read hits and 3.1\texttimes\ fewer L3
cache read misses than the other benchmarks.

\begin{figure}[!ht]
  \centering
  \subfloat[L3 Cache Read Misses]{
    \includegraphics[width=0.5\linewidth]{locality-performance/cache-stress-test-cache-misses}
    \label{fig:locality-performance-cache-stress-test-cache-misses}
  }
  \subfloat[L3 Cache Read Hits]{
    \includegraphics[width=0.5\linewidth]{locality-performance/cache-stress-test-cache-hits}
    \label{fig:locality-performance-cache-stress-test-cache-hits}
  }
  \caption{\emph{Cache Stress Test} with L3 cache read misses and hits
    normalized to \emph{best locality}}
  \label{fig:locality-performance-cache-stress-test-cache}
\end{figure}

The intervals implementation of the benchmarks with \emph{ignorant},
\emph{random} and \emph{worst locality} is faster compared to the
multi-threaded benchmark implementations of the same
localities. 

A reason for this is the use \emph{Work-Stealing Places}. They have a
positive effect on the runtime due to their load-balancing
properties. As the number of cache hits and misses shows, they do not
produce counter-productive steals for the \emph{Cache Stress Test}
benchmarks.

\subsection{Merge Sort}
\label{sec:locality-performance-merge-sort}

\emph{Merge Sort} is representative of many programs that use a
recursive divide-and-conquer paradigm. Our \emph{Merge Sort}
benchmark...

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\linewidth]{locality-performance/mergesort}
  \caption{Merge Sort: Best locality}
  \label{fig:locality-performance-mergesort}
\end{figure}

\todo{Finish section ``Merge Sort''}


\subsection{Block Matrix Multiplication}
\label{sec:locality-performance-block-matrix-multiplication}

The \emph{Block Matrix Multiplication} benchmark multiplies two $n
\times n$ matrices $A$ and $B$ using locality-aware intervals. The
implementation employs the following recursion to calculate the matrix
$C$:

\begin{eqnarray*}
  \begin{pmatrix}
    C_{00} & C_{01} \\
    C_{10} & C_{11}
  \end{pmatrix}
  &
  =
  &
  \begin{pmatrix}
    A_{00} & A_{01} \\
    A_{10} & A_{11}
  \end{pmatrix}
  \cdot
  \begin{pmatrix}
    B_{00} & B_{01} \\
    B_{10} & B_{11}
  \end{pmatrix}
  \\
  &
  =
  &
  \begin{pmatrix}
    A_{00} \cdot B_{00} + A_{01} \cdot B_{10} & A_{00} \cdot B_{01} + A_{01} \cdot B_{11} \\
    A_{10} \cdot B_{00} + A_{11} \cdot B_{10} & A_{10} \cdot B_{01} + A_{11} \cdot B_{11} \\
  \end{pmatrix}
\end{eqnarray*}

Thus, the $n \times n$ matrix multiplication can be reduced to 8
multiplications and 4 additions of $(n/2) \times (n/2)$
submatrices. The 8 multiplications can be calculated in parallel and
when they are done, the 4 additions can be computed in parallel too.

We run the \emph{Block Matrix Multiplication} benchmark to multiply
two random $2048 \times 2048$ matrices. A $2048 \times 2048$ matrix
needs about 16 MB of memory and should just about fit in the L3 cache
of the two processors of our test machine. The benchmark recursively
splits the $2048 \times 2048$ matrices $A$ and $B$ into quadrants
until they reach size $32 \times 32$ and are multiplied using the
well-known sequential matrix multiplication algorithm.

We implement two variants of the benchmark: \emph{best locality} and
\emph{worst locality}. Figure
\ref{fig:locality-performance-block-matrix-multiplication-locality}
shows the division of matrix quadrants between places for both
variants:

\begin{description}
\item[Best Locality:] The \emph{best locality} benchmark runs all
  addition and multiplication intervals of the matrix quadrants 0 and
  3 in \emph{place 0} and and the ones of the quadrants 1 and 2 in
  \emph{place 1}. This way the places are able to share their local L3
  cache in an efficient way.
\item[Worst Locality:] The \emph{worst locality} benchmark runs the
  multiplication and addition intervals in different places destroying
  cache locality.
\end{description}

\begin{figure}[!ht]
  \centering
  \subfloat[Best Locality]{
    \includegraphics[width=0.5\linewidth]{locality-performance/block-matrix-multiplication-best-locality}
    \label{fig:locality-performance-block-matrix-multiplication-best-locality}
  }
  \subfloat[Worst Locality]{
    \includegraphics[width=0.5\linewidth]{locality-performance/block-matrix-multiplication-worst-locality}
    \label{fig:locality-performance-block-matrix-multiplication-worst-locality}
  }
  \caption{\emph{Block Matrix Multiplication} quadrants with \emph{best} and \emph{worst locality}}
  \label{fig:locality-performance-block-matrix-multiplication-locality}
\end{figure}

Table \ref{tab:locality-performance-block-matrix-multiplication} shows
the execution times and the speedups over the sequential algorithm for
the \emph{best locality} and \emph{worst locality} benchmark
implementations. The implementation with \emph{best locality} is the
fastest and provides the largest speedup.

\begin{table}[htb]
  \centering
  \begin{tabular}{ln{2}{3}n{1}{2}}
    \toprule
    & {Runtime (in seconds)} & {Speedup (over sequential)} \\\midrule
    \emph{Best Locality} & 4.690 & 3.97 \\
    \emph{Worst Locality} & 5.399 & 3.45 \\
    \emph{Sequential Implementation}\hspace{0.5cm} & 18.632 & 1 \\\bottomrule
  \end{tabular}
  \caption{\emph{Block Matrix Multiplication} execution times and speedups over sequential implementation}
  \label{tab:locality-performance-block-matrix-multiplication}
\end{table}

Figure \ref{fig:locality-performance-block-matrix-multiplication}
illustrates the execution time of the \emph{worst locality}
implementation normalized to that of the \emph{best locality}
implementation. The \emph{best locality} implementation shows a
speedup over the \emph{worst locality} of about 1.15\texttimes.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.65\linewidth]{locality-performance/block-matrix-multiplication}
  \caption{\emph{Block Matrix Multiplication} with execution times normalized to
    \emph{best locality}}
  \label{fig:locality-performance-block-matrix-multiplication}
\end{figure}

Table
\ref{tab:locality-performance-block-matrix-multiplication-cache-hits-misses}
lists the number of L3 cache read hits and misses. In Figure
\ref{fig:locality-performance-block-matrix-multiplication} they are
shown normalized to the measurements of the \emph{best locality}
implementation. Compared to the other benchmarks, the \emph{best
  locality} has 1.15\texttimes\ more L3 cache read hits and up to
1.3\texttimes\ fewer L3 cache read misses.

\begin{table}[htb]
  \centering
  \begin{tabular}{ln{4}{0}n{4}{0}}
    \toprule
     & {L3 Cache Read Hits} & {L3 Cache Read Misses} \\\midrule
    \emph{Best Locality}\hspace{1cm} & 1461  & 360 \\
    \emph{Worst Locality} & 1273 & 476 \\\bottomrule
  \end{tabular}
  \caption[\emph{Block Matrix Multiplication} L3 cache read hits and misses]
  {\emph{Block Matrix Multiplication} L3 cache read hits and misses (rounded to the nearest million)}
  \label{tab:locality-performance-block-matrix-multiplication-cache-hits-misses}
\end{table}

\begin{figure}[!ht]
  \centering
  \subfloat[L3 Cache Read Hits]{
    \includegraphics[width=0.5\linewidth]{locality-performance/block-matrix-multiplication-cache-hits}
    \label{fig:locality-performance-block-matrix-multiplication-cache-hits}
  }
  \subfloat[L3 Cache Read Misses]{
    \includegraphics[width=0.5\linewidth]{locality-performance/block-matrix-multiplication-cache-misses}
    \label{fig:locality-performance-block-matrix-multiplication-cache-misses}
  }
  \caption{\emph{Block Matrix Multiplication} with L3 cache read hits
    and misses normalized to \emph{best locality}}
  \label{fig:locality-performance-block-matrix-multiplication-cache}
\end{figure}

\todo{Finish section ``Block Matrix Multiplication''}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
