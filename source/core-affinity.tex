%==============================================================================
% core-affinity.tex
%==============================================================================

\chapter{Setting Core Affinity of Java Threads}
\label{chap:appendix-core-affinity}

The intervals scheduler implements each worker as a separate Java
thread. For the locality-aware scheduler we need to bind each worker
to a separate core.

In recent Java Virtual Machines, threads are implemented with native
threads, so a Java program using threads is no different from a native
program using threads: A Java thread is just a thread belonging to a
JVM process. This means there is a 1-to-1 correspondence between Java
and native threads. When using the GNU C library on Linux, native
threads are implemented with NPTL (Native POSIX Threads Library). NPTL
is also an 1-to-1 implementation, meaning that each thread maps to a
kernel scheduling entity (see Figure
\ref{fig:core-affinity-thread-mapping}).

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}
    [node distance=0.8cm,
    start chain=going below,]
    \node[box, join] {Java Thread};
    \node[box, join] {Native POSIX Thread};
    \node[box, join] {Kernel Scheduling Entity};
  \end{tikzpicture}
  \caption{Linux 1-to-1 thread mapping}
  \label{fig:core-affinity-thread-mapping}
\end{figure}

Unfortunately the Java Threads API does not expose the ability to set
the CPU or core affinity despite numerous use cases where setting the
affinity of threads would be desirable \cite{Love2003, Dow2005,
  Foong2008}.  There exists a request for enhancement
\cite{Oracle1999} on this issue but it got set to the state
\emph{``Closed, Will Not Fix''}.


\section{Implementation}
\label{sec:appendix-core-affinity-implementation}

For binding the workers to a specific core, we wrote a small JNI
library (see Listing \ref{lst:core-affinity} for the API). The method
\lstinline!set(int physicalUnit)!  (line
\ref{lst:core-affinity-set-unit}) is used to bind the current thread
to a physical unit. With \lstinline!set(int[] physicalUnits)! the
current thread can be bound to several physical units, for example to
a node in a NUMA system (line \ref{lst:core-affinity-set-node}). For
debugging purposes we also implemented the method \lstinline!get()!
which returns a boolean array whose elements are true if the current
thread has an affinity set to the corresponding physical unit (line
\ref{lst:core-affinity-get}).

\lstinputlisting[style=FloatNumbers,
  caption={\lstinline{Affinity} class with interface for the native methods}, 
  label=lst:core-affinity]{
    ../listings/core-affinity/Affinity.java 
}

Listing \ref{lst:core-affinity-jni-header} contains the native method
declarations which are implemented in Listing
\ref{lst:core-affinity-jni-set} and
\ref{lst:core-affinity-jni-get}. Line
\ref{lst:core-affinity-jni-h-set-unit} declares
\lstinline!set(int physicalUnit)!. On line
\ref{lst:core-affinity-jni-h-set-node} we declared the method
\lstinline!set(int[] physicalUnits)! and \lstinline!get()! is declared
on line \ref{lst:core-affinity-jni-h-get}.

\lstinputlisting[style=SkipNumbersC, 
  caption={\lstinline{Affinity} class: JNI C header}, 
  label=lst:core-affinity-jni-header]{
    ../listings/core-affinity/ch_ethz_hwloc_Affinity.h 
}

\newpage

\lstinputlisting[style=FloatNumbersC, 
  caption={\lstinline{Affinity} class: JNI C implementation to set the affinity},
  label=lst:core-affinity-jni-set]{
    ../listings/core-affinity/ch_ethz_hwloc_Affinity_set.c 
}

\newpage

The implementation for setting the affinity is shown in Listing
\ref{lst:core-affinity-jni-set}. When setting the affinity, we first
initialize the CPU set structure (lines
\ref{lst:core-affinity-jni-set-unit-init-cpuset} and
\ref{lst:core-affinity-jni-set-node-init-cpuset}) and then we set it
to the specified physical units (lines
\ref{lst:core-affinity-jni-set-unit-set-cpuset} and
\ref{lst:core-affinity-jni-set-unit-set-cpuset}). Actual setting of
the affinity is done in function
\lstinline!set_affinity(JNIEnv *env, const cpu_set_t *cpuset)! on lines
\ref{lst:core-affinity-jni-set-impl-start} --
\ref{lst:core-affinity-jni-set-impl-end}.

To get the thread ID, we use the \lstinline!pthread_self()! function
(line \ref{lst:core-affinity-jni-set-impl-pthread-self}). The function
\lstinline!pthread_setaffinity_np()! (line
\ref{lst:core-affinity-jni-set-impl-set}) sets the CPU affinity mask
of the thread to the CPU set pointed to by \lstinline!cpuset!.  If the
call is successful, and the thread is not currently running on one of
the CPUs in \lstinline!cpuset!, then it is migrated to one of those
CPUs. If there is an error, \lstinline!pthread_setaffinity_np()!
returs a nonzero error number and we throw an exception (line
\ref{lst:core-affinity-jni-set-impl-set-error}).

Listing \ref{lst:core-affinity-jni-get} shows the implementation for
getting the affinity of a thread. This method is mainly used for
debugging purposes. We use \lstinline!pthread_self()! (line
\ref{lst:core-affinity-jni-get-impl-pthread-self}) to get the thread
ID and then call function \lstinline!pthread_getaffinity_np()!  (line
\ref{lst:core-affinity-jni-get-impl-get}). The
\lstinline!pthread_getaffinity_np()! function returns the CPU affinity
mask of the thread thread in the buffer pointed to by
\lstinline!cpuset!.

\lstinputlisting[style=FloatNumbersC, 
  caption={\lstinline{Affinity} class: JNI C implementation to get the affinity},
  label=lst:core-affinity-jni-get]{
    ../listings/core-affinity/ch_ethz_hwloc_Affinity_get.c 
}


\section{Restrictions}
\label{sec:appendix-core-affinity-restrictions}

\subsubsection{Portability}

As we are directly using functions provided by POSIX threads, our
implementation is not portable across operating systems that do not
support the POSIX standard. To make our library portable, it could be
rewritten using Portable Linux Processor Affinity (PLPA)
\cite{OpenMPI2010a} or Portable Hardware Locality (hwloc)
\cite{OpenMPI2010}.

\subsubsection{Data Locality}

By setting the core affinity of threads, we only control the locality
of the work but we do not have control over data locality.

On a NUMA system every processor in the system has a local memory that
provides low access latency and high bandwidth, and a remote memory
that is considerably slower to access.

In the Java HotSpot VM, the NUMA-aware allocator has been implemented
to provide automatic memory placement optimisations for Java
applications \cite{Masamitsu2008, Oracle2010, Humble2010}. On Linux,
the implementation is based on \cite{Kleen2004}. It can be enabled by
using the option \verb!-XX:+UseNUMA!.

The allocator controls the eden space of the young generation of the
heap, where most of the new objects are created. It divides the space
into regions each of which is placed in the memory of a specific
node. The allocator relies on a hypothesis that a thread that
allocates the object will be the most likely to use the object. To
ensure the fastest access to the new object, the allocator places it
in the region local to the allocating thread. The regions can be
dynamically resized to reflect the allocation rate of the application
threads running on different nodes.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 