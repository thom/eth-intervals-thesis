%==============================================================================
% locality-conclusions.tex
%==============================================================================

\chapter{Conclusions and Future Work}
\label{chap:locality-conclusions}

\section{Conclusions}
\label{sec:locality-conclusions-and-future-work-conclusions}

\todo{Finish section ``Conclusions''}


\section{Future Work}
\label{sec:locality-conclusions-and-future-work-future-work}

Scheduling of lightweight threads is a very broad area of research and
there are many possible directions we could further extend our work.

Future work should improve the API of \emph{Work-Stealing Places} and
locality-aware intervals. In the current implemenation, places have to
be manually configured for each system. This should be automated by
making the underlying machine transparent to the user. To make our
library portable, we could use \emph{Portable Linux Processor Affinity
  (PLPA)} \cite{OpenMPI2010a} or \emph{Portable Hardware Locality
  (hwloc)} \cite{OpenMPI2010}. The way programmers have to provide
locality hints to intervals is not very convenient. Future work should
make using locality-awareness more intuitive.

Our locality-aware intervals scheduler depends on the heuristics of
the NUMA-aware allocator implemented in Java HotSpot VM to provide
automatic memory placement optimizations. Further research should be
done in extending \emph{Work-Stealing Places} to co-locate tasks and
data \cite{HJ, Charles2005, Saraswat2010}. It might be interesting to
see how \emph{Work-Stealing Places} would benefit from supporting
multiple levels of a memory hierarchy as it is done by
\textcite{Yan2009}.

Load balancing across work-stealing places could lead to
counter-productive stealing. One possible direction for future work
would be to avoid counter-productive steals. \textcite{Agarwal2008}
present a novel framework for statically establishing place locality
in a work-stealing scheduler. The implementation of Threading Building
Blocks \cite{Contreras2008, Reinders2007} uses a work-stealing
scheduler which tries to limit unneeded migration of tasks and
data. \textcite{Gaud2010} introduce heuristics for \emph{time-left
  stealing} and \emph{penalty-aware stealing} which only require
little involvement from the application programmers.

Every worker threads executes on another core which eliminates direct
contention between them. But they still share their assigned core with
other processes in the system. To further enhance our locality-aware
scheduler, we could use online contention
detection. \textcite{Mars2010} describe how online contention
detection can be used to dynamically reduce or increase the number of
worker threads depending on the system load. \textcite{Agrawal2007}
develop and analyze \lstinline!A-STEAL!, an adaptive work-stealing
algorithm with parallelism feedback.

Another possible direction for future research would be exploring
\emph{Parallel Depth-First Scheduling} as a possible replacement for
\emph{Work-Stealing Scheduling} in intervals. In parallel depth-first
scheduling, tasks are assigned priorities in the same ordering as they
would be executed in a sequential program. This means, tasks that
would be executed earlier are given higher priorities than those that
would be executed later. As a result, parallel depth-first scheduling
tends to employ constructive cache sharing \cite{Liaskovitis2006,
  Chen2007} as it co-schedules threads in a way that simulates the
sequential execution order.


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
