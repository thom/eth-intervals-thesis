%==============================================================================
% locality-conclusions.tex
%==============================================================================

\chapter{Conclusions and Future Work}
\label{chap:locality-conclusions-and-future-work}

\section{Conclusions}
\label{sec:locality-conclusions-and-future-work-conclusions}

In this thesis, we introduced LASSI, a locality-aware scheduler for
intervals. It is designed for locality-aware scheduling using locality
hints provided by the programmer. Instead of employing work-stealing
workers, LASSI uses \emph{Work-Stealing Places}. \emph{Work-Stealing
  Places} are a novel data structure providing locality-awareness to
the intervals scheduler.

Our experimental results show that \emph{best locality} placement of
intervals can achieve up to $1.15\times$ speedup over \emph{worst} or
\emph{ignorant locality} placement. Cache hits can be increased by up
to $1.5\times$ and cache misses can be reduced by up to $3.1\times$
for the benchmarks and platform studied in this thesis.

\todo{Correct speedups, and cache hits and misses}

While LASSI can improve performance of programs written with locality
in mind, it is important to note that the performance of existing
locality-ignorant programs is comparable to the original scheduler
implementation.

\todo{Finish section ``Conclusions''}


\section{Future Work}
\label{sec:locality-conclusions-and-future-work-future-work}

Scheduling of lightweight threads is a very broad area of research and
there are many potential directions we could further extend our work.

A possible area of future work would be to improve the API of
\emph{Work-Stealing Places} and locality-aware intervals. In the
current implementation, places have to be manually configured for each
system. This should be automated by making the underlying machine
transparent to the user. To make our library portable, we could use
\emph{Portable Linux Processor Affinity (PLPA)} \cite{OpenMPI2010a} or
\emph{Portable Hardware Locality (hwloc)} \cite{OpenMPI2010}. The way
programmers have to provide locality hints to intervals is not very
convenient and should be made more intuitive.

LASSI depends on the heuristics of the NUMA-aware allocator
implemented in Java HotSpot VM to provide automatic memory placement
optimizations. Further research could be done in extending
\emph{Work-Stealing Places} to co-locate tasks and data \cite{HJ,
  Charles2005, Saraswat2010}. It might be interesting to see how
\emph{Work-Stealing Places} would benefit from supporting multiple
levels of a memory hierarchy as it is done by
\textcite{Yan2009}. \emph{Hierarchical Place Trees} are designed to
run on both homogeneous (CPU) and heterogeneous (GPU) multicore
parallel systems.

Load balancing across work-stealing places could lead to
counter-productive stealing. One possible direction for future work
would be to avoid counter-productive steals. \textcite{Agarwal2008}
present a novel framework for statically establishing place locality
in a work-stealing scheduler. The implementation of Threading Building
Blocks \cite{Contreras2008, Reinders2007} uses a work-stealing
scheduler which tries to limit unneeded migration of tasks and
data. \textcite{Gaud2010} introduce heuristics for \emph{time-left
  stealing} and \emph{penalty-aware stealing} which only require
little involvement from the application programmers.

Every worker thread executes on another core which eliminates direct
contention between them. But they still share their assigned core with
other processes in the system. To further enhance our locality-aware
scheduler, we could employ online contention
detection. \textcite{Mars2010} describe how online contention
detection can be used to dynamically reduce or increase the number of
worker threads depending on the system load. \textcite{Agrawal2007}
develop and analyze \lstinline!A-STEAL!, an adaptive work-stealing
algorithm with parallelism feedback.

Another possible direction for future research would be to explore
\emph{Parallel Depth-First Scheduling} as a possible replacement for
\emph{Work-Stealing Scheduling} in intervals. In parallel depth-first
scheduling, tasks are assigned priorities in the same ordering they
would be executed in a sequential program. As a result, parallel
depth-first scheduling tends to employ constructive cache sharing
\cite{Liaskovitis2006, Chen2007} as it co-schedules threads in a way
that simulates the sequential execution order.


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 
